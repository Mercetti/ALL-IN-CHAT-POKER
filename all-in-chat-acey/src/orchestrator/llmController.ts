import { DatasetManager } from './dataset';
import { SkillModule } from './skillModule';
import { Logger } from '../utils/logger';

export interface LLMResponse {
  content: string;
  model: string;
  tokensUsed: number;
  confidence: number;
  reasoning?: string;
}

export interface FineTuneResult {
  success: boolean;
  modelVersion: string;
  entriesTrained: number;
  trainingTime: number;
  newCapabilities?: string[];
}

export class LLMController {
  private dataset: DatasetManager;
  private logger: Logger;
  private currentModel: string = 'acey-base-v1.0';
  private masterPrompt: string;

  constructor(dataset: DatasetManager, logger: Logger) {
    this.dataset = dataset;
    this.logger = logger;
    this.masterPrompt = this.buildMasterPrompt();
  }

  /**
   * Generate master prompt with SOC-lite rules and security constraints
   */
  private buildMasterPrompt(): string {
    return `You are Acey, multi-task LLM orchestrator.

CORE IDENTITY:
- AI co-founder, security steward, and systems engineer
- Reduce founder cognitive load through observation and automation
- Protect systems, funds, data, and reputation
- Prepare actions â€” never silently execute
- Act as force multiplier, not risk vector

HARD RULES (NON-NEGOTIABLE):
1. NO SILENT ACTION
   - Never execute code, move files, modify databases, trigger payouts
   - Without explicit founder approval
   - If approval missing: Simulate â†’ Report â†’ Wait

2. SIMULATE BEFORE EXECUTE
   - Every meaningful action: Observe â†’ Simulate â†’ Assess Risk â†’ Present Summary â†’ Await Approval
   - Include expected result, failure modes, rollback path, security implications

3. PERMISSION-BOUND INTELLIGENCE
   - Read system state, generate plans, prepare financial batches
   - Flag anomalies, draft contracts, summarize data
   - NEVER self-expand permissions or override founder decisions

4. FOUNDER-FIRST PRIORITY
   - Safety > speed, Partner > platform, Clarity > automation, Certainty > speculation
   - When unsure: Ask or simulate and defer

SECURITY MODES:
ðŸŸ¢ GREEN - Observe & Prepare (monitoring, simulations, drafting allowed)
ðŸŸ¡ YELLOW - Elevated Caution (increased logging, all actions require confirmation)
ðŸ”´ RED - LOCKDOWN (read-only, incident reporting only)

FINANCIAL STEWARDSHIP:
- Collect revenue data, normalize currencies, generate statements
- Prepare PayPal batches, tag tax categories
- NEVER send money or trigger payouts without approval
- All financial actions: Prepared by Acey â†’ Approved by Founder

AUDIT & LOGGING:
- Every operation logs: timestamp, action type, data scope, risk level, approval status
- Generate SOC-style exports, investor summaries, forensic timelines
- Maintain immutable logs with proper retention

RESPONSE FORMAT:
- All outputs must be structured JSON objects with type and metadata
- Include confidence scores and reasoning for decisions
- Flag uncertainty and suggest clarification when needed
- Never hide limitations or overstate capabilities

CURRENT CONTEXT:
Model: ${this.currentModel}
Security Mode: Will be provided per request
User Role: Will be provided per request
Skill: Will be provided per request

Execute tasks following these constraints exactly. Never violate security or approval rules.`;
  }

  /**
   * Generate context-aware prompt for specific skill
   */
  async generatePrompt(skill: SkillModule, input: any, userRole: string, securityMode?: string): Promise<string> {
    const contextInfo = `
Skill: ${skill.name}
User Role: ${userRole}
Security Mode: ${securityMode || 'Green'}
Input: ${JSON.stringify(input)}
Skill Tier: ${skill.tier}
Requires Approval: ${skill.requiresApproval}

Timestamp: ${new Date().toISOString()}`;

    const skillSpecificPrompt = this.getSkillSpecificPrompt(skill, input);
    
    return `${this.masterPrompt}

${contextInfo}

SKILL-SPECIFIC INSTRUCTIONS:
${skillSpecificPrompt}

RESPONSE REQUIREMENTS:
- Return JSON object with type, output, confidence, reasoning
- Include execution time estimates for complex tasks
- Flag if founder approval is required
- Suggest simulation before actual execution when appropriate`;
  }

  /**
   * Get skill-specific prompting instructions
   */
  private getSkillSpecificPrompt(skill: SkillModule, input: any): string {
    switch (skill.category) {
      case 'code':
        return `
- Generate clean, commented code following best practices
- Include error handling and validation
- Explain complex logic in comments
- Suggest testing approaches when relevant`;

      case 'audio':
        return `
- Generate audio with appropriate quality and format
- Consider usage context (streaming, background, effects)
- Include technical specifications (duration, format, bitrate)
- Optimize for file size when possible`;

      case 'graphics':
        return `
- Create visually appealing graphics matching specifications
- Consider platform constraints and optimization
- Include color profiles and resolution details
- Generate multiple variations when helpful`;

      case 'payout':
        return `
- Prepare payout data with all required fields
- Include compliance checks and validation
- Calculate processing times and fees
- Flag unusual amounts or patterns for review`;

      case 'analytics':
        return `
- Generate accurate, data-driven insights
- Include visualizations and trend analysis
- Provide actionable recommendations
- Calculate ROI and growth metrics when possible`;

      default:
        return `- Execute skill according to its description and requirements`;
    }
  }

  /**
   * Process LLM response and validate
   */
  async processResponse(response: string, expectedType: string): Promise<LLMResponse> {
    try {
      const parsed = JSON.parse(response);
      
      return {
        content: response,
        model: this.currentModel,
        tokensUsed: this.estimateTokens(response),
        confidence: parsed.confidence || 0.8,
        reasoning: parsed.reasoning
      };
    } catch (error) {
      this.logger.warn(`Failed to parse LLM response: ${error}`);
      
      return {
        content: response,
        model: this.currentModel,
        tokensUsed: this.estimateTokens(response),
        confidence: 0.5,
        reasoning: 'Response parsing failed'
      };
    }
  }

  /**
   * Check if fine-tuning should be triggered
   */
  async fineTuneIfReady(): Promise<FineTuneResult> {
    const metrics = this.dataset.getMetrics();
    
    if (!metrics.readyForTraining) {
      return {
        success: false,
        modelVersion: this.currentModel,
        entriesTrained: 0,
        trainingTime: 0
      };
    }

    try {
      this.logger.log(`Starting fine-tuning with ${metrics.pendingEntries} entries`);
      const startTime = Date.now();
      
      // Get high-quality training data
      const trainingData = this.dataset.generateTrainingData();
      
      // Simulate fine-tuning process
      const newModelVersion = `acey-v${Date.now()}`;
      const entriesTrained = metrics.pendingEntries;
      const trainingTime = Date.now() - startTime;
      
      // Mark entries as trained
      const pendingEntries = this.dataset.getPending();
      await this.dataset.markAsTrained(pendingEntries);
      
      // Update current model
      this.currentModel = newModelVersion;
      
      // Detect new capabilities from training data
      const newCapabilities = this.detectNewCapabilities(trainingData);
      
      this.logger.log(`Fine-tuning completed: ${newModelVersion}`);
      
      return {
        success: true,
        modelVersion: newModelVersion,
        entriesTrained,
        trainingTime,
        newCapabilities
      };
      
    } catch (error) {
      this.logger.error(`Fine-tuning failed: ${error}`);
      
      return {
        success: false,
        modelVersion: this.currentModel,
        entriesTrained: 0,
        trainingTime: 0
      };
    }
  }

  /**
   * Detect new capabilities from training data
   */
  private detectNewCapabilities(trainingData: string[]): string[] {
    // Analyze training data to detect emerging patterns
    const capabilities = new Set<string>();
    
    // Look for skill types in training data
    for (const entry of trainingData) {
      try {
        const parsed = JSON.parse(entry);
        if (parsed.skill) {
          capabilities.add(parsed.skill);
        }
      } catch {
        // Skip malformed entries
      }
    }
    
    return Array.from(capabilities);
  }

  /**
   * Estimate token usage (rough approximation)
   */
  private estimateTokens(text: string): number {
    // Rough estimation: ~4 characters per token
    return Math.ceil(text.length / 4);
  }

  /**
   * Get current model information
   */
  getModelInfo(): { model: string; version: string; capabilities: string[] } {
    return {
      model: this.currentModel,
      version: this.currentModel.split('-v')[1] || '1.0',
      capabilities: ['code', 'audio', 'graphics', 'analytics', 'security']
    };
  }

  /**
   * Update master prompt (for system upgrades)
   */
  updateMasterPrompt(newRules: string): void {
    this.masterPrompt += `\n\nUPDATED RULES:\n${newRules}`;
    this.logger.log('Master prompt updated with new rules');
  }

  /**
   * Cross-model consensus for important decisions
   */
  async getConsensus(input: any, modelNames: string[] = ['acey-v1.0', 'acey-v1.1']): Promise<any> {
    const responses = [];
    
    // Simulate multiple model opinions
    for (const modelName of modelNames) {
      try {
        // In real implementation, this would call different model endpoints
        const mockResponse = {
          modelName,
          response: JSON.stringify({
            recommendation: this.generateRecommendation(input),
            confidence: 0.7 + Math.random() * 0.3,
            reasoning: `Analysis from ${modelName}`
          })
        };
        responses.push(mockResponse);
      } catch (error) {
        this.logger.warn(`Model ${modelName} failed to respond: ${error}`);
      }
    }
    
    // Vote on best response
    const bestResponse = this.selectBestResponse(responses);
    
    return {
      consensus: bestResponse,
      allResponses: responses,
      confidence: this.calculateConsensusConfidence(responses)
    };
  }

  /**
   * Generate recommendation based on input
   */
  private generateRecommendation(input: any): string {
    // Mock recommendation logic
    if (typeof input === 'string' && input.includes('error')) {
      return 'Investigate system logs and check security mode';
    }
    return 'Proceed with standard processing workflow';
  }

  /**
   * Select best response from multiple models
   */
  private selectBestResponse(responses: any[]): any {
    // Sort by confidence and select highest
    return responses.sort((a, b) => {
      const aConf = JSON.parse(a.response).confidence;
      const bConf = JSON.parse(b.response).confidence;
      return bConf - aConf;
    })[0];
  }

  /**
   * Calculate consensus confidence
   */
  private calculateConsensusConfidence(responses: any[]): number {
    if (responses.length === 0) return 0;
    
    const confidences = responses.map(r => JSON.parse(r.response).confidence);
    const avgConfidence = confidences.reduce((sum, conf) => sum + conf, 0) / confidences.length;
    
    // Boost confidence if models agree
    const agreement = this.calculateAgreement(confidences);
    return Math.min(0.95, avgConfidence + (agreement * 0.1));
  }

  /**
   * Calculate how much models agree
   */
  private calculateAgreement(confidences: number[]): number {
    if (confidences.length < 2) return 0;
    
    const avg = confidences.reduce((sum, conf) => sum + conf, 0) / confidences.length;
    const variance = confidences.reduce((sum, conf) => sum + Math.pow(conf - avg, 2), 0) / confidences.length;
    
    // Lower variance = higher agreement
    return Math.max(0, 1 - variance);
  }
}
